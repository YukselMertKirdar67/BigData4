# ETL Pipeline with Apache NiFi and MongoDB (AWS EC2)
## üìå Project Overview

This project implements an ETL (Extract-Transform-Load) pipeline using Apache NiFi to collect data from two different cloud data sources and consolidate them into MongoDB in JSON format.
The system demonstrates distributed data ingestion, transformation and analytics.

## üß± System Architecture

Data Sources:
- EC2 Instance 1 ‚Üí MongoDB
- EC2 Instance 2 ‚Üí MySQL
ETL Tool:
- Apache NiFi
Destination:
- Local MongoDB

## üìÇ Data Sources

CSV files provided:
- expense.csv
- emp.csv
- dept.csv
Initial loading:
- expense.csv stored in MongoDB (EC2)
- emp.csv and dept.csv stored in MySQL (EC2)

## üîÑ ETL Pipeline (NiFi Flow)

The NiFi pipeline performs:
1Ô∏è‚É£ Extract data from MongoDB (EC2)

2Ô∏è‚É£ Extract data from MySQL (EC2)

3Ô∏è‚É£ Convert records into JSON format

4Ô∏è‚É£ Merge/transform data where necessary

5Ô∏è‚É£ Load processed data into local MongoDB database (`targetdb`)

All collections share consistent naming.

## üóÑÔ∏è Destination Database

Database Name:
big25
Collections:
- expense
- emp
- dept
All data stored in JSON format.

## üß† Analytical Queries (MongoDB Aggregation)

The following analytical questions were answered:

 ### 1Ô∏è‚É£ Who (with name) spends how much for food or appliances?
 Using aggregation with `$lookup` and `$group`.
 ### 2Ô∏è‚É£ Which department made the most purchases?
 Aggregation pipeline joining:
 - expense
 - emp
 - dept
 ### 3Ô∏è‚É£ Who spent the most?
 Grouping expenses by employee and sorting descending.

## üìä Example Aggregation (Simplified)

```javascript
db.expense.aggregate([
  {
    $lookup: {
      from: "emp",
      localField: "empno",
      foreignField: "empno",
      as: "employee"
    }
  },
  { $unwind: "$employee" },
  {
    $group: {
      _id: "$employee.ename",
      totalSpent: { $sum: "$amount" }
    }
  },
  { $sort: { totalSpent: -1 } }
])
```

## üõ†Ô∏è Technologies Used

-AWS EC2
-MongoDB
-MySQL
-Apache NiFi
-JSON Data Processing
-MongoDB Aggregation Framework

## üöÄ How to Run

1Ô∏è‚É£ Start MongoDB (source EC2)

2Ô∏è‚É£ Start MySQL (source EC2)

3Ô∏è‚É£ Start Apache NiFi

4Ô∏è‚É£ Execute NiFi pipeline

5Ô∏è‚É£ Verify data loaded into local MongoDB (targetdb)

6Ô∏è‚É£ Run aggregation queries

## üéØ Learning Outcomes

-Cloud-based distributed data ingestion

-ETL pipeline design using NiFi

-Data transformation to JSON

-MongoDB aggregation & joins ($lookup)

-Multi-source data consolidation
